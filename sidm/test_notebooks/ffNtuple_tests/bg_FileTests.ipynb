{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66321b-b603-4d42-9db2-47314d017aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "# columnar analysis\n",
    "from coffea import processor\n",
    "import awkward as ak\n",
    "from dask.distributed import Client\n",
    "# local\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../..')) \n",
    "from sidm.tools import ffschema, sidm_processor, utilities, scaleout\n",
    "# always reload local modules to pick up changes during development\n",
    "importlib.reload(ffschema)\n",
    "importlib.reload(sidm_processor)\n",
    "importlib.reload(utilities)\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "\n",
    "# Load style sheet\n",
    "# plt.style.use(hep.style.CMS)  # or ATLAS/LHCb2\n",
    "\n",
    "# h, bins = np.histogram(np.random.random(1000))\n",
    "# fig, ax = plt.subplots()\n",
    "# hep.histplot(h, bins)\n",
    "\n",
    "utilities.set_plot_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da785e8b-419d-438f-bf11-70bc18355e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = scaleout.make_dask_client(\"tls://localhost:8786\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a97fb57-9d60-49be-8bd1-b31cfa0833f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIDM_samples = [\n",
    "    #\"2Mu2E_100GeV_1p2GeV_9p6mm\", \n",
    "    #\"4Mu_100GeV_1p2GeV_9p6mm\",\n",
    "    \n",
    "    #\"2Mu2E_1000GeV_0p25GeV_0p02mm\",\n",
    "    #\"4Mu_1000GeV_0p25GeV_0p02mm\"\n",
    "]\n",
    "\n",
    "samples = [\n",
    "    \"DYJetsToLL_M10to50\", # Background\n",
    "    \"DYJetsToLL_M50\",\n",
    "    \n",
    "    \"QCD_Pt15to20\", #Works\n",
    "    \"QCD_Pt20to30\", #issue, needs many files to fill all histograms\n",
    "    \"QCD_Pt30to50\", #Broken, throws KeyError: 'akjet_ak4PFJetsCHS_jetid' --- Fixed by change in ffschema\n",
    "    #\"QCD_Pt50to80\", #Works\n",
    "    #\"QCD_Pt80to120\", #Works\n",
    "    #\"QCD_Pt120to170\", # Really broken, Exception: Failed processing file: WorkItem(dataset='QCD_Pt120to170' ...)\n",
    "    #\"QCD_Pt170to300\", #Works\n",
    "    #\"QCD_Pt300to470\", #Works\n",
    "    #\"QCD_Pt470to600\", #Works\n",
    "    #\"QCD_Pt600to800\", #Works\n",
    "    #\"QCD_Pt800to1000\", #Works\n",
    "    #\"QCD_Pt1000toInf\", #Works\n",
    "    \n",
    "    \"TTJets\",\n",
    "    \"WW\",\n",
    "    \"WZ\",\n",
    "    \"ZZ\",\n",
    "]\n",
    "\n",
    "for sample in SIDM_samples:\n",
    "    samples.append(sample)\n",
    "\n",
    "fileset = utilities.make_fileset(samples, \"ffntuple_v2\") #max_files argument was removed, so it defaults to use all the files in each sample\n",
    "#fileset = utilities.make_fileset(samples, \"ffntuple_v2\", max_files=1) #CHANGED: background appears to use v2 ntuples instead of v4\n",
    "\n",
    "#print(fileset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beab38e-cc3b-48a0-b3f5-44569b65dcdd",
   "metadata": {},
   "source": [
    "The error in QCD_Pt30to50, as well as the error in making the histogram \"lj_pfiso\", is based on a missing attribute in ffschema. The issue was fixed by adding a condition that the attribute could only be retrieved from branch_forms if it exists in branch_forms initially (ffschema.py line 191). The error in QCD_Pt120to170, and intermittently in other filesets is caused by samples without lepton jets in them. When a file has no lepton jets, the key \"ntuple_ljs\" returns a keyError. This is caused by the lack of \"evts.pfjets\" in the ntuples and cannot be corrected. A possible fix may be adding a condition to only process events if this category is not empty, but it is not resolved yet.\n",
    "\n",
    "There is also an error in dask. I'm not sure of the source, but it cannot run any files (except the first two SIDM samples and all dibosons listed) as far as I know, giving a runtime error based on \n",
    "\n",
    "\"RuntimeError: Expected LorentzVector L1TOHLT_DoubleL2Mu25NoVtx_2Cha to end with 'p4' or 'rawP4'.\"\n",
    "The cited LorentzVector is different depending on file. I have seen the following ones appear in the errors:\n",
    "\n",
    "L1TOHLT_DoubleL2Mu25NoVtx_2Cha (for various samples)\n",
    "\n",
    "L1TOHLT_DoubleL2Mu25NoVtx_2Cha_CosmicSeed (for various samples)\n",
    "\n",
    "TOHLT_DoubleL2Mu25NoVtx_2Cha_Eta2p4 (for QCD, but QCD has also had the cosmicSeed vector)\n",
    "\n",
    "NOTE: This results in the message \"Expected LorentzVector TOHLT_DoubleL2Mu25NoVtx_2Cha_Eta2p4 to end with 'p4' or 'rawP4',\" even though the vector does end in 'p4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a2a98-5c7c-4a0d-93db-f245d7c45f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner = processor.Runner(\n",
    "    #executor=processor.IterativeExecutor(),\n",
    "    executor=processor.DaskExecutor(client=client),\n",
    "    #executor=processor.FuturesExecutor(),\n",
    "    schema=ffschema.FFSchema,\n",
    "    #maxchunks=1,\n",
    ")\n",
    "\n",
    "channels = [\n",
    "            \"baseNoLj\"\n",
    "           ] # NOTE: the channel used determines the cuts applied. baseNoLj removes the checks for multiple jets.\n",
    "\n",
    "hist_menu = utilities.load_yaml(\"../configs/hist_collections.yaml\")\n",
    "collection = utilities.flatten(hist_menu[\"base\"]) #To change the histograms used, swap \"base\" for the other collections\n",
    "print(collection)\n",
    "\n",
    "p = sidm_processor.SidmProcessor(\n",
    "    channels, [\"base\"]) # not sure if base_plus_gen applies to the background\n",
    "\n",
    "# test if processor is serializable\n",
    "import coffea.util as coffea_util\n",
    "coffea_util.save(p, \"processor.coffea\")\n",
    "print(coffea_util.load(\"processor.coffea\"))\n",
    "\n",
    "\n",
    "output = runner.run(fileset, treename=\"ffNtuplizer/ffNtuple\", processor_instance=p)\n",
    "out = output[\"out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3e154-dd60-4c3b-813d-244a7e1741c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.subplots(1, 1, figsize=(20,14))\n",
    "for i in range(len(samples)):\n",
    "    utilities.plot(out[samples[i]][\"hists\"][\"lj_pfIsolation07\"][\"baseNoLj\", :1200j], yerr=False, density=True, flow='none')\n",
    "plt.legend(samples)\n",
    "plt.title(\"lj_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaab8ce-9a76-421c-a9e9-fa097e0d0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing, combines background samples into larger sets.\n",
    "# This applies to cutflows and to histograms\n",
    "hist_set = hist_choice\n",
    "hist_menu = utilities.load_yaml(\"../configs/hist_collections.yaml\")\n",
    "collection = utilities.flatten(hist_menu[hist_set]) #To change the histograms used, swap \"base\" for the other collections\n",
    "\n",
    "sample_list = [\"DY_Jets\", \"QCD_Jets\", \"DiBoson_Jets\", \"TTJets\", \"Total Background\"]\n",
    "\n",
    "for sample in samples:\n",
    "    if not(sample[0] == 'D') and not(sample[0] == 'Q') and not((sample[0] == 'W' or sample[0] == 'Z')) and not(sample[0] == 'T'):\n",
    "        sample_list.append(sample)\n",
    "\n",
    "#Combine Drell-Yan\n",
    "keys = list(output['out'][\"DYJetsToLL_M10to50\"][\"cutflow\"].keys())[:]\n",
    "DY_Cutflow = {k: output['out'][\"DYJetsToLL_M10to50\"][\"cutflow\"][k] for k in keys}\n",
    "    \n",
    "keys = list(output['out'][\"DYJetsToLL_M10to50\"][\"hists\"].keys())[:]\n",
    "DY_Hists = {k: output['out'][\"DYJetsToLL_M10to50\"][\"hists\"][k] for k in keys}\n",
    "    \n",
    "keys = list(output['out'][\"DYJetsToLL_M50\"][\"cutflow\"].keys())[:]\n",
    "temp = {k: output['out'][\"DYJetsToLL_M50\"][\"cutflow\"][k] for k in keys}\n",
    "for channel in channels:\n",
    "    DY_Cutflow[channel] = DY_Cutflow[channel] + temp[channel]\n",
    "keys = list(output['out'][\"DYJetsToLL_M50\"][\"hists\"].keys())[:]\n",
    "temp = {k: output['out'][\"DYJetsToLL_M50\"][\"hists\"][k] for k in keys}    \n",
    "for hist_name in collection:\n",
    "    DY_Hists[hist_name] = DY_Hists[hist_name] + temp[hist_name]\n",
    "\n",
    "#Combine QCD\n",
    "keys = list(output['out'][\"QCD_Pt15to20\"][\"cutflow\"].keys())[:]\n",
    "QCD_Cutflow = {k: output['out'][\"QCD_Pt15to20\"][\"cutflow\"][k] for k in keys}\n",
    "keys = list(output['out'][\"QCD_Pt15to20\"][\"hists\"].keys())[:]\n",
    "QCD_Hists = {k: output['out'][\"QCD_Pt15to20\"][\"hists\"][k] for k in keys}\n",
    "    \n",
    "for sample in samples:\n",
    "    if (sample[0] == 'Q') and (sample != \"QCD_Pt15to20\"):\n",
    "        keys = list(output['out'][sample][\"cutflow\"].keys())[:]\n",
    "        temp = {k: output['out'][sample][\"cutflow\"][k] for k in keys}\n",
    "        for channel in channels:\n",
    "            QCD_Cutflow[channel] = QCD_Cutflow[channel] + temp[channel]\n",
    "                \n",
    "        keys = list(output['out'][sample][\"hists\"].keys())[:]\n",
    "        temp = {k: output['out'][sample][\"hists\"][k] for k in keys}\n",
    "        for hist_name in collection:\n",
    "            QCD_Hists[hist_name] = QCD_Hists[hist_name] + temp[hist_name]\n",
    "\n",
    "#Combine diboson\n",
    "keys = list(output['out'][\"WW\"][\"hists\"].keys())[:]\n",
    "DiBoson_Hists = {k: output['out'][\"WW\"][\"hists\"][k] for k in keys}\n",
    "\n",
    "keys = list(output['out'][\"WW\"][\"cutflow\"].keys())[:]\n",
    "DiBoson_Cutflow = {k: output['out'][\"WW\"][\"cutflow\"][k] for k in keys}\n",
    "\n",
    "for sample in [\"WZ\", \"ZZ\"]:\n",
    "    keys = list(output['out'][\"WZ\"][\"cutflow\"].keys())[:]\n",
    "    temp = {k: output['out'][\"WZ\"][\"cutflow\"][k] for k in keys}\n",
    "    for channel in channels:\n",
    "        DiBoson_Cutflow[channel] = DiBoson_Cutflow[channel] + temp[channel]\n",
    "\n",
    "    keys = list(output['out'][sample][\"hists\"].keys())[:]\n",
    "    temp = {k: output['out'][sample][\"hists\"][k] for k in keys}\n",
    "    for hist_name in collection:\n",
    "        DiBoson_Hists[hist_name] = DiBoson_Hists[hist_name] + temp[hist_name]\n",
    "\n",
    "#Add ttbar\n",
    "keys = list(output['out'][\"TTJets\"][\"hists\"].keys())[:]\n",
    "TT_Hists = {k: output['out'][\"TTJets\"][\"hists\"][k] for k in keys}\n",
    "\n",
    "keys = list(output['out'][\"TTJets\"][\"cutflow\"].keys())[:]\n",
    "TT_Cutflow = {k: output['out'][\"TTJets\"][\"cutflow\"][k] for k in keys}\n",
    "\n",
    "#Combine total background\n",
    "keys = list(output['out'][\"DYJetsToLL_M10to50\"][\"hists\"].keys())[:]\n",
    "bg_Hists = {k: output['out'][\"DYJetsToLL_M10to50\"][\"hists\"][k] for k in keys}\n",
    "\n",
    "keys = list(output['out'][\"DYJetsToLL_M10to50\"][\"cutflow\"].keys())[:]\n",
    "bg_Cutflow = {k: output['out'][\"DYJetsToLL_M10to50\"][\"cutflow\"][k] for k in keys}\n",
    "\n",
    "for sample in samples:\n",
    "    if ((sample[0] == 'D') or (sample[0] == 'Q') or (sample[0] == 'W') or (sample[0] == 'Z') or (sample[0] == 'T')) and (sample != \"DYJetsToLL_M10to50\"):\n",
    "        keys = list(output['out'][sample][\"cutflow\"].keys())[:]\n",
    "        temp = {k: output['out'][sample][\"cutflow\"][k] for k in keys}\n",
    "        for channel in channels:\n",
    "            bg_Cutflow[channel] = bg_Cutflow[channel] + temp[channel]\n",
    "\n",
    "        keys = list(output['out'][sample][\"hists\"].keys())[:]\n",
    "        temp = {k: output['out'][sample][\"hists\"][k] for k in keys}\n",
    "        for hist_name in collection:\n",
    "            bg_Hists[hist_name] = bg_Hists[hist_name] + temp[hist_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec70d9d1-36bb-469a-b432-e6c2f36e27de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b5b35-b23f-4791-bdbe-609c76bf9f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bg_Cutflow[\"baseNoLj\"].print_table(fraction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a23a3-8eac-4b15-ae07-ba4061507c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1, 1, figsize=(20,14))\n",
    "for sample in samples:\n",
    "    utilities.plot(out[sample][\"hists\"][\"lj_pfiso\"][\"baseNoLj\", :1200j], yerr=False, density=True, flow='none')\n",
    "plt.legend(samples)\n",
    "plt.title(\"lj_pfiso\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
